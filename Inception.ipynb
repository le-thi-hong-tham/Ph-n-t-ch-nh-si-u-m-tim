{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport torch\nfrom torchvision import datasets, models, transforms\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport torch.optim as optim\nimport torchvision\nfrom torch.autograd import Variable\nimport time\nimport copy\nimport cv2 \nimport numpy as np\ninput_path = \"../input/data-chamber/DATA_CHAMBER_2021/\" \nuse_gpu = torch.cuda.is_available()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-21T08:01:39.188197Z","iopub.execute_input":"2021-11-21T08:01:39.188482Z","iopub.status.idle":"2021-11-21T08:01:39.198775Z","shell.execute_reply.started":"2021-11-21T08:01:39.188432Z","shell.execute_reply":"2021-11-21T08:01:39.197991Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class ImageFolderWithPaths(datasets.ImageFolder):\n    \n    def __getitem__(self, index):\n        # this is what ImageFolder normally returns \n        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n        # the image file path\n        path = self.imgs[index][0]\n        # make a new tuple that includes original and the path\n        tuple_with_path = (original_tuple + (path,))\n        return tuple_with_path","metadata":{"execution":{"iopub.status.busy":"2021-11-21T08:01:39.200134Z","iopub.execute_input":"2021-11-21T08:01:39.200701Z","iopub.status.idle":"2021-11-21T08:01:39.208651Z","shell.execute_reply.started":"2021-11-21T08:01:39.200649Z","shell.execute_reply":"2021-11-21T08:01:39.207973Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def set_parameter_requires_grad(model, feature_extracting):\n    if feature_extracting:\n        for param in model.parameters():\n            param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2021-11-21T08:01:39.209996Z","iopub.execute_input":"2021-11-21T08:01:39.210595Z","iopub.status.idle":"2021-11-21T08:01:39.223706Z","shell.execute_reply.started":"2021-11-21T08:01:39.210466Z","shell.execute_reply":"2021-11-21T08:01:39.223095Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def initialize_model(model_name, num_classes, feature_extract = False, use_pretrained=True):\n    \n    model_ft = None\n    input_size = 0\n\n    if model_name == \"resnet18\":\n        \"\"\" Resnet18\n        \"\"\"\n        model_ft = models.resnet18(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.fc.in_features\n        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n        input_size = 224\n        \n    elif model_name == \"resnet50\":\n        \"\"\" Resnet50\n        \"\"\"\n        model_ft = models.resnet50(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.fc.in_features\n        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n        input_size = 224\n    elif model_name == \"alexnet\":\n        \"\"\" Alexnet\n        \"\"\"\n        model_ft = models.alexnet(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.classifier[6].in_features\n        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n        input_size = 224\n\n    elif model_name == \"vgg\":\n        \"\"\" VGG19_bn\n        \"\"\"\n        model_ft = models.vgg19_bn().load_state_dict(torch.load(\"../input/vgg19bn/vgg19_bn.pth\"))\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_features = vgg16.classifier[6].in_features\n        features = list(vgg16.classifier.children())[:-1] # Remove last layer\n        features.extend([nn.Linear(num_features, len(num_classes))]) # Add our layer with 4 outputs\n        vgg16.classifier = nn.Sequential(*features) # Replace the model classifier\n        input_size = 224\n\n    elif model_name == \"squeezenet\":\n        \"\"\" Squeezenet\n        \"\"\"\n        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n        model_ft.num_classes = num_classes\n        input_size = 224\n\n    elif model_name == \"densenet\":\n        \"\"\" Densenet\n        \"\"\"\n        model_ft = models.densenet121(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.classifier.in_features\n        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n        input_size = 224\n\n    elif model_name == \"inception\":\n        \"\"\" Inception v3\n        Be careful, expects (299,299) sized images and has auxiliary output\n        \"\"\"\n        model_ft = models.inception_v3(pretrained=False)\n        model_ft.load_state_dict(torch.load('../input/pretrained-pytorch-models/inception_v3_google-1a9a5a14.pth'))\n        set_parameter_requires_grad(model_ft, feature_extract)\n        # Handle the auxilary net\n        num_ftrs = model_ft.AuxLogits.fc.in_features\n        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n        # Handle the primary net\n        num_ftrs = model_ft.fc.in_features\n        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n        input_size = 299\n\n    else:\n        print(\"Invalid model name, exiting...\")\n        exit()\n\n    return model_ft, input_size\n\nmodel_ft, input_size = initialize_model('inception', 3,feature_extract = False, use_pretrained=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-21T08:01:39.225296Z","iopub.execute_input":"2021-11-21T08:01:39.225911Z","iopub.status.idle":"2021-11-21T08:01:42.006454Z","shell.execute_reply.started":"2021-11-21T08:01:39.225546Z","shell.execute_reply":"2021-11-21T08:01:42.005643Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def opening(img):\n    kernel = np.ones((5, 5), np.uint8)\n    img_erosion = cv2.erode(img, kernel, iterations=1)\n    img_dilation = cv2.dilate(img_erosion, kernel, iterations=1)\n    return img_dilation\ndef denoise(img):\n    \n    denoise_img = cv2.bilateralFilter(img, 15, 75, 75)\n    return denoise_img","metadata":{"execution":{"iopub.status.busy":"2021-11-21T08:01:42.007893Z","iopub.execute_input":"2021-11-21T08:01:42.008175Z","iopub.status.idle":"2021-11-21T08:01:42.014231Z","shell.execute_reply.started":"2021-11-21T08:01:42.008130Z","shell.execute_reply":"2021-11-21T08:01:42.013516Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def apply_brightness_contrast(input_img, brightness = 0, contrast = 0):\n    if brightness != 0:\n        if brightness > 0:\n            shadow = brightness\n            highlight = 255\n        else:\n            shadow = 0\n            highlight = 255 + brightness\n        alpha_b = (highlight - shadow)/255\n        gamma_b = shadow\n        \n        buf = cv2.addWeighted(input_img, alpha_b, input_img, 0, gamma_b)\n    else:\n        buf = input_img.copy()\n    \n    if contrast != 0:\n        f = 131*(contrast + 127)/(127*(131-contrast))\n        alpha_c = f\n        gamma_c = 127*(1-f)\n        \n        buf = cv2.addWeighted(buf, alpha_c, buf, 0, gamma_c)\n\n    return buf","metadata":{"execution":{"iopub.status.busy":"2021-11-21T08:01:42.015419Z","iopub.execute_input":"2021-11-21T08:01:42.015865Z","iopub.status.idle":"2021-11-21T08:01:42.027276Z","shell.execute_reply.started":"2021-11-21T08:01:42.015815Z","shell.execute_reply":"2021-11-21T08:01:42.026477Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nfrom matplotlib import cm\ndef preprocessing(img):\n    return Image.fromarray(np.uint8(apply_brightness_contrast(opening(denoise(np.array(img))),0,16)))\n","metadata":{"execution":{"iopub.status.busy":"2021-11-21T08:01:42.028372Z","iopub.execute_input":"2021-11-21T08:01:42.028763Z","iopub.status.idle":"2021-11-21T08:01:42.036870Z","shell.execute_reply.started":"2021-11-21T08:01:42.028703Z","shell.execute_reply":"2021-11-21T08:01:42.036136Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"\ndata_transforms = {\n    'train': transforms.Compose([\n        preprocessing,\n        transforms.Resize(input_size),\n        transforms.CenterCrop(input_size),\n    \n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  \n    ]),\n    'validation': transforms.Compose([\n        preprocessing,\n        transforms.Resize(input_size),\n        transforms.CenterCrop(input_size),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\n\n\nimage_datasets = {\n    'train':\n    ImageFolderWithPaths(input_path + 'train', data_transforms['train']),\n    'validation': \n    ImageFolderWithPaths(input_path + 'test', data_transforms['validation'])\n}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train','validation']}\n\ndataloaders = {\n    'train':\n    torch.utils.data.DataLoader(image_datasets['train'],\n                                batch_size=32,\n                                shuffle=True,\n                                num_workers=4),  # for Kaggle\n    'validation':\n    torch.utils.data.DataLoader(image_datasets['validation'],\n                                batch_size=32,\n                                shuffle=True,\n                                num_workers=4)  # for Kaggle\n}\nclass_names = image_datasets['train'].classes\n\n# See some statistics\nprint(dataloaders)\nlen(dataloaders['train'])","metadata":{"execution":{"iopub.status.busy":"2021-11-21T08:01:42.038203Z","iopub.execute_input":"2021-11-21T08:01:42.038726Z","iopub.status.idle":"2021-11-21T08:01:43.000314Z","shell.execute_reply.started":"2021-11-21T08:01:42.038449Z","shell.execute_reply":"2021-11-21T08:01:42.999553Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nplt.ion()   # interactive mode\n\ndef imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n\n\n# Get a batch of training data\ninputs, classes,_ = next(iter(dataloaders['train']))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-21T08:01:43.001642Z","iopub.execute_input":"2021-11-21T08:01:43.002151Z","iopub.status.idle":"2021-11-21T08:01:51.671445Z","shell.execute_reply.started":"2021-11-21T08:01:43.002100Z","shell.execute_reply":"2021-11-21T08:01:51.670465Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, num_epochs=2, is_inception=False):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    loss_values = []\n    acc_values = []\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train','validation']:\n            if phase == 'train':\n                scheduler.step()\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels,_ in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    \n                    if is_inception and phase == 'train':\n                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n                        outputs, aux_outputs = model(inputs)\n                        loss1 = criterion(outputs, labels)\n                        loss2 = criterion(aux_outputs, labels)\n                        loss = loss1 + 0.4*loss2\n                    else:\n                        outputs = model(inputs)\n                        loss = criterion(outputs, labels)\n                    \n                    _, preds = torch.max(outputs, 1)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n                del inputs,labels\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n            loss_values.append(epoch_loss)\n            acc_values.append(epoch_acc)\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'validation' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model,acc_values,loss_values","metadata":{"execution":{"iopub.status.busy":"2021-11-21T08:01:51.672826Z","iopub.execute_input":"2021-11-21T08:01:51.673122Z","iopub.status.idle":"2021-11-21T08:01:51.699606Z","shell.execute_reply.started":"2021-11-21T08:01:51.673074Z","shell.execute_reply":"2021-11-21T08:01:51.698796Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def visualize_model(model, num_images=6):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    fig = plt.figure()\n\n    with torch.no_grad():\n        for i, (inputs, labels,_) in enumerate(dataloaders['validation']):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n\n            for j in range(inputs.size()[0]):\n                images_so_far += 1\n                ax = plt.subplot(num_images//2, 2, images_so_far)\n                ax.axis('off')\n                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n                imshow(inputs.cpu().data[j])\n\n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T08:01:51.704214Z","iopub.execute_input":"2021-11-21T08:01:51.707070Z","iopub.status.idle":"2021-11-21T08:01:51.718976Z","shell.execute_reply.started":"2021-11-21T08:01:51.707007Z","shell.execute_reply":"2021-11-21T08:01:51.718176Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"\ndef test_model(model, criterion, optimizer):\n    labels_input=list()\n    labels_output=list()\n    vid_id = list()\n    for phase in ['validation']:\n        model.eval()\n\n        running_loss = 0.0\n        running_corrects = 0\n\n        for inputs, labels, fname in dataloaders[phase]:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            labels_input= labels_input + labels.tolist()\n            for f in fname:\n                vid_id.append(f.split('/')[-1].split('.')[0].split('_')[0])\n            outputs = model(inputs)\n            \n            loss = criterion(outputs, labels)\n            _, preds = torch.max(outputs, 1)\n            \n            labels_output= labels_output + preds.tolist()\n    return labels_input,labels_output,vid_id\n            ","metadata":{"execution":{"iopub.status.busy":"2021-11-21T08:01:51.723878Z","iopub.execute_input":"2021-11-21T08:01:51.727260Z","iopub.status.idle":"2021-11-21T08:01:51.736236Z","shell.execute_reply.started":"2021-11-21T08:01:51.727182Z","shell.execute_reply":"2021-11-21T08:01:51.735534Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def plot_history(history,loss,acc): \n    fig, ax1 = plt.subplots()\n    \n    ax1.plot(loss, 'r', label=\"training loss\")\n    ax1.grid(True)\n    ax1.set_xlabel('iteration')\n    ax1.set_ylabel('loss', color='r')\n    ax1.legend(loc=\"best\", fontsize=9)    \n    ax1.tick_params('y', colors='r')\n\n    ax2 = ax1.twinx()\n    ax2.plot(acc, 'b', label=\"training acc\")\n    ax2.legend(loc=\"lower right\", fontsize=9)\n    ax2.set_ylabel('acc', color='b')        \n    ax2.tick_params('y', colors='b')","metadata":{"execution":{"iopub.status.busy":"2021-11-21T08:01:51.737515Z","iopub.execute_input":"2021-11-21T08:01:51.737875Z","iopub.status.idle":"2021-11-21T08:01:51.746306Z","shell.execute_reply.started":"2021-11-21T08:01:51.737828Z","shell.execute_reply":"2021-11-21T08:01:51.745611Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.optim import lr_scheduler\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nmodel_ft = model_ft.to(device)\n\nparams_to_update = []\nfor name,param in model_ft.named_parameters():\n    if param.requires_grad == True:\n        params_to_update.append(param)\n\noptimizer_conv = optim.SGD(params_to_update, lr=0.01, momentum=0.9)\n\ncriterion = nn.CrossEntropyLoss()\n# Decay LR by a factor of 0.1 every epoch\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=1, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T08:01:51.747819Z","iopub.execute_input":"2021-11-21T08:01:51.748332Z","iopub.status.idle":"2021-11-21T08:01:51.804694Z","shell.execute_reply.started":"2021-11-21T08:01:51.748157Z","shell.execute_reply":"2021-11-21T08:01:51.804112Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"model_ft,acc,loss = train_model(model_ft, criterion, optimizer_conv,\n                         exp_lr_scheduler, num_epochs=10, is_inception=True) ","metadata":{"execution":{"iopub.status.busy":"2021-11-21T08:01:51.806541Z","iopub.execute_input":"2021-11-21T08:01:51.807042Z","iopub.status.idle":"2021-11-21T09:09:27.931223Z","shell.execute_reply.started":"2021-11-21T08:01:51.806984Z","shell.execute_reply":"2021-11-21T09:09:27.930094Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"plot_history(model_ft,loss,acc)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T09:09:27.933152Z","iopub.execute_input":"2021-11-21T09:09:27.933677Z","iopub.status.idle":"2021-11-21T09:09:28.362914Z","shell.execute_reply.started":"2021-11-21T09:09:27.933614Z","shell.execute_reply":"2021-11-21T09:09:28.362204Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"visualize_model(model_ft)\n\nplt.ioff()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-21T09:09:28.364026Z","iopub.execute_input":"2021-11-21T09:09:28.364457Z","iopub.status.idle":"2021-11-21T09:09:41.299996Z","shell.execute_reply.started":"2021-11-21T09:09:28.364407Z","shell.execute_reply":"2021-11-21T09:09:41.299157Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"y_true,y_pred,vid_id = test_model(model_ft, criterion, optimizer_conv)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-21T09:09:41.301426Z","iopub.execute_input":"2021-11-21T09:09:41.301732Z","iopub.status.idle":"2021-11-21T09:10:59.654692Z","shell.execute_reply.started":"2021-11-21T09:09:41.301685Z","shell.execute_reply":"2021-11-21T09:10:59.653781Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(y_true,y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T09:10:59.656599Z","iopub.execute_input":"2021-11-21T09:10:59.656896Z","iopub.status.idle":"2021-11-21T09:11:00.120888Z","shell.execute_reply.started":"2021-11-21T09:10:59.656847Z","shell.execute_reply":"2021-11-21T09:11:00.119855Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport glob\n\n\ndf = pd.DataFrame(list(zip(y_true,y_pred,vid_id)),columns =['y_true','y_pred','vid_id'])\ndf.to_csv('df.csv',encoding='utf-8',index=False)\n\nvid_list = list(set(df['vid_id'].values))\ny_true = []\ny_pred = []\nfor vid in vid_list:\n    #print(vid)\n    tmp_df = df[df['vid_id']==vid]\n    #print(len(tmp_df))\n    vid_pred = tmp_df['y_pred'].mode().values[0]\n    vid_label = tmp_df['y_true'].mode().values[0]\n    y_true.append(vid_label)\n    y_pred.append(vid_pred)\n   ","metadata":{"execution":{"iopub.status.busy":"2021-11-21T09:11:00.125184Z","iopub.execute_input":"2021-11-21T09:11:00.127459Z","iopub.status.idle":"2021-11-21T09:11:00.702644Z","shell.execute_reply.started":"2021-11-21T09:11:00.125438Z","shell.execute_reply":"2021-11-21T09:11:00.701662Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T09:11:00.707197Z","iopub.execute_input":"2021-11-21T09:11:00.707731Z","iopub.status.idle":"2021-11-21T09:11:00.737487Z","shell.execute_reply.started":"2021-11-21T09:11:00.707441Z","shell.execute_reply":"2021-11-21T09:11:00.736843Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"accuracy_score(y_true,y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T09:11:00.741397Z","iopub.execute_input":"2021-11-21T09:11:00.743529Z","iopub.status.idle":"2021-11-21T09:11:00.754483Z","shell.execute_reply.started":"2021-11-21T09:11:00.743479Z","shell.execute_reply":"2021-11-21T09:11:00.753398Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"import glob\npath = '../input/data-chamber/DATA_CHAMBER_2021/train/'\nclass_count = {}\nlabel = []\nfor f in ['2C','3C','4C']:\n    class_count[f] = len(glob.glob(f'../input/data-chamber/DATA_CHAMBER_2021/train/{f}/*'))\n    label = label + [f]*class_count[f]\n    #print(f'Number sample per class {f}: {class_count[f]}')\n    ","metadata":{"execution":{"iopub.status.busy":"2021-11-21T09:11:00.758439Z","iopub.execute_input":"2021-11-21T09:11:00.760596Z","iopub.status.idle":"2021-11-21T09:11:00.814964Z","shell.execute_reply.started":"2021-11-21T09:11:00.760532Z","shell.execute_reply":"2021-11-21T09:11:00.814003Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\ndef countplot_comparison(feature):\n    s1 = sns.countplot(feature)\n    s1.set_title(\"Overview data\")\ncountplot_comparison(label)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T09:11:00.816255Z","iopub.execute_input":"2021-11-21T09:11:00.816722Z","iopub.status.idle":"2021-11-21T09:11:01.271470Z","shell.execute_reply.started":"2021-11-21T09:11:00.816670Z","shell.execute_reply":"2021-11-21T09:11:01.270555Z"},"trusted":true},"execution_count":39,"outputs":[]}]}