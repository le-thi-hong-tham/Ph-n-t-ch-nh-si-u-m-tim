{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport torch\nfrom torchvision import datasets, models, transforms\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport torch.optim as optim\nimport torchvision\nfrom torch.autograd import Variable\nimport time\nimport copy\nimport cv2 \nimport numpy as np\n","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:09:44.436946Z","iopub.execute_input":"2021-11-21T07:09:44.437343Z","iopub.status.idle":"2021-11-21T07:09:44.446727Z","shell.execute_reply.started":"2021-11-21T07:09:44.437213Z","shell.execute_reply":"2021-11-21T07:09:44.445857Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# !pip install albumentations\n#import albumentations as A","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:09:44.447939Z","iopub.execute_input":"2021-11-21T07:09:44.448413Z","iopub.status.idle":"2021-11-21T07:09:44.472185Z","shell.execute_reply.started":"2021-11-21T07:09:44.448341Z","shell.execute_reply":"2021-11-21T07:09:44.471029Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"import os\nfrom os import listdir, makedirs, getcwd, remove\nfrom os.path import join, exists, expanduser\n\ncache_dir = expanduser(join('~', '.torch'))\n\nif not exists(cache_dir):\n    makedirs(cache_dir)\nmodels_dir = join(cache_dir, 'models')\nif not exists(models_dir):\n    makedirs(models_dir)\n    \n!cp ../input/pretrained-pytorch-models/* ~/.torch/models/\n!ls ~/.torch/models","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:09:44.473529Z","iopub.execute_input":"2021-11-21T07:09:44.474018Z","iopub.status.idle":"2021-11-21T07:09:46.710473Z","shell.execute_reply.started":"2021-11-21T07:09:44.473809Z","shell.execute_reply":"2021-11-21T07:09:46.709565Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"class ImageFolderWithPaths(datasets.ImageFolder):\n   \n    def __getitem__(self, index):\n        # this is what ImageFolder normally returns \n        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n        # the image file path\n        path = self.imgs[index][0]\n        # make a new tuple that includes original and the path\n        tuple_with_path = (original_tuple + (path,))\n        return tuple_with_path","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:09:46.713800Z","iopub.execute_input":"2021-11-21T07:09:46.714044Z","iopub.status.idle":"2021-11-21T07:09:46.720444Z","shell.execute_reply.started":"2021-11-21T07:09:46.713998Z","shell.execute_reply":"2021-11-21T07:09:46.719686Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def set_parameter_requires_grad(model, feature_extracting):\n    if feature_extracting:\n        for param in model.parameters():\n            param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:09:46.721655Z","iopub.execute_input":"2021-11-21T07:09:46.722154Z","iopub.status.idle":"2021-11-21T07:09:47.946949Z","shell.execute_reply.started":"2021-11-21T07:09:46.722109Z","shell.execute_reply":"2021-11-21T07:09:47.945951Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def initialize_model(model_name, num_classes, feature_extract = False, use_pretrained=True):\n\n    model_ft = None\n    input_size = 0\n\n    if model_name == \"resnet18\":\n        \"\"\" Resnet18\n        \"\"\"\n        model_ft = models.resnet18(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.fc.in_features\n        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n        input_size = 224\n        \n    elif model_name == \"resnet50\":\n        \"\"\" Resnet50\n        \"\"\"\n        model_ft = models.resnet50(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.fc.in_features\n        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n        input_size = 224\n\n    elif model_name == \"alexnet\":\n        \"\"\" Alexnet\n        \"\"\"\n        model_ft = models.alexnet(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.classifier[6].in_features\n        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n        input_size = 224\n\n    elif model_name == \"vgg19_bn\":\n        \"\"\" VGG16_bn\n        \"\"\"\n        model_ft = models.vgg19_bn().load_state_dict(torch.load(\"../input/vgg19bn/vgg19_bn.pth\"))\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_features = vgg16.classifier[6].in_features\n        features = list(vgg16.classifier.children())[:-1] # Remove last layer\n        features.extend([nn.Linear(num_features, len(num_classes))]) # Add our layer with 4 outputs\n        vgg16.classifier = nn.Sequential(*features) # Replace the model classifier\n        input_size = 224\n    elif model_name == \"vgg16_bn\":\n        \"\"\" VGG16_bn\n        \"\"\"\n        model_ft = models.vgg16_bn().load_state_dict(torch.load(\"../input/vgg16bn/vgg16_bn.pth\"))\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_features = vgg16.classifier[6].in_features\n        features = list(vgg16.classifier.children())[:-1] # Remove last layer\n        features.extend([nn.Linear(num_features, len(num_classes))]) # Add our layer with 4 outputs\n        vgg16.classifier = nn.Sequential(*features) # Replace the model classifier\n        input_size = 224\n\n    elif model_name == \"squeezenet\":\n        \"\"\" Squeezenet\n        \"\"\"\n        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n        model_ft.num_classes = num_classes\n        input_size = 224\n\n    elif model_name == \"densenet\":\n        \"\"\" Densenet\n        \"\"\"\n        model_ft = models.densenet121(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.classifier.in_features\n        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n        input_size = 224\n\n    elif model_name == \"inception\":\n        \"\"\" Inception v3\n        Be careful, expects (299,299) sized images and has auxiliary output\n        \"\"\"\n        model_ft = models.inception_v3(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        # Handle the auxilary net\n        num_ftrs = model_ft.AuxLogits.fc.in_features\n        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n        # Handle the primary net\n        num_ftrs = model_ft.fc.in_features\n        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n        input_size = 299\n\n    else:\n        print(\"Invalid model name, exiting...\")\n        exit()\n\n    return model_ft, input_size\n\n# Initialize the model for this run\nmodel_ft, input_size = initialize_model('resnet50',3,feature_extract = False, use_pretrained=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:09:47.948968Z","iopub.execute_input":"2021-11-21T07:09:47.949601Z","iopub.status.idle":"2021-11-21T07:09:48.730899Z","shell.execute_reply.started":"2021-11-21T07:09:47.949343Z","shell.execute_reply":"2021-11-21T07:09:48.730145Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def opening(img):\n    kernel = np.ones((5, 5), np.uint8)\n    img_erosion = cv2.erode(img, kernel, iterations=1)\n    img_dilation = cv2.dilate(img_erosion, kernel, iterations=1)\n    return img_dilation\ndef denoise(img):\n    #denoise_img = cv2.medianBlur(img,9)\n    denoise_img = cv2.bilateralFilter(img, 15, 75, 75)\n    return denoise_img","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:09:48.733441Z","iopub.execute_input":"2021-11-21T07:09:48.733984Z","iopub.status.idle":"2021-11-21T07:09:48.739700Z","shell.execute_reply.started":"2021-11-21T07:09:48.733933Z","shell.execute_reply":"2021-11-21T07:09:48.738940Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def apply_brightness_contrast(input_img, brightness = 0, contrast = 0):\n    if brightness != 0:\n        if brightness > 0:\n            shadow = brightness\n            highlight = 255\n        else:\n            shadow = 0\n            highlight = 255 + brightness\n        alpha_b = (highlight - shadow)/255\n        gamma_b = shadow\n        \n        buf = cv2.addWeighted(input_img, alpha_b, input_img, 0, gamma_b)\n    else:\n        buf = input_img.copy()\n    \n    if contrast != 0:\n        f = 131*(contrast + 127)/(127*(131-contrast))\n        alpha_c = f\n        gamma_c = 127*(1-f)\n        \n        buf = cv2.addWeighted(buf, alpha_c, buf, 0, gamma_c)\n\n    return buf","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:09:48.741120Z","iopub.execute_input":"2021-11-21T07:09:48.742526Z","iopub.status.idle":"2021-11-21T07:09:48.755466Z","shell.execute_reply.started":"2021-11-21T07:09:48.742471Z","shell.execute_reply":"2021-11-21T07:09:48.754618Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nfrom matplotlib import cm\ndef preprocessing(img):\n    return Image.fromarray(np.uint8(apply_brightness_contrast(opening(denoise(np.array(img))),0,16)))\n","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:09:48.757185Z","iopub.execute_input":"2021-11-21T07:09:48.757821Z","iopub.status.idle":"2021-11-21T07:09:48.764751Z","shell.execute_reply.started":"2021-11-21T07:09:48.757448Z","shell.execute_reply":"2021-11-21T07:09:48.763917Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize(input_size),\n        transforms.CenterCrop(input_size),\n        preprocessing,\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'validation': transforms.Compose([\n        transforms.Resize(input_size),\n        transforms.CenterCrop(input_size),\n        preprocessing,\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n}\n\n\n\n\nimage_datasets = {\n    'train': \n    ImageFolderWithPaths(input_path + 'train', data_transforms['train']),\n    'validation': \n    ImageFolderWithPaths(input_path + 'test', data_transforms['validation'])\n}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train','validation']}\n\ndataloaders = {\n    'train':\n    torch.utils.data.DataLoader(image_datasets['train'],\n                                batch_size=32,\n                                shuffle=True,\n                                num_workers=4),  # for Kaggle\n    'validation':\n    torch.utils.data.DataLoader(image_datasets['validation'],\n                                batch_size=32,\n                                shuffle=False,\n                                num_workers=4) \n}\nclass_names = image_datasets['train'].classes\n\n# See some statistics\nprint(dataloaders)\nlen(dataloaders['train'])","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:09:48.766225Z","iopub.execute_input":"2021-11-21T07:09:48.766753Z","iopub.status.idle":"2021-11-21T07:09:52.310069Z","shell.execute_reply.started":"2021-11-21T07:09:48.766569Z","shell.execute_reply":"2021-11-21T07:09:52.309329Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nplt.ion()   # interactive mode\n\ndef imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  \n    \n# Get a batch of training data\ninputs, classes,_ = next(iter(dataloaders['train']))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:09:52.311237Z","iopub.execute_input":"2021-11-21T07:09:52.311659Z","iopub.status.idle":"2021-11-21T07:09:55.390160Z","shell.execute_reply.started":"2021-11-21T07:09:52.311487Z","shell.execute_reply":"2021-11-21T07:09:55.389111Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, num_epochs=2, is_inception=False):\n    since = time.time()\n    \n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    loss_values = []\n    acc_values = []\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train','validation']:\n            train_batches = len(dataloaders[phase])\n            if phase == 'train':\n                scheduler.step()\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for i,(inputs, labels,_) in enumerate(dataloaders[phase]):\n                print(\"\\rTraining batch {}/{}\".format(i+1, train_batches), end='', flush=True)\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    \n                    if is_inception and phase == 'train':\n                        \n                        outputs, aux_outputs = model(inputs)\n                        loss1 = criterion(outputs, labels)\n                        loss2 = criterion(aux_outputs, labels)\n                        loss = loss1 + 0.4*loss2\n                    else:\n                        outputs = model(inputs)\n                        loss = criterion(outputs, labels)\n                    \n                    _, preds = torch.max(outputs, 1)\n\n                \n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n            loss_values.append(epoch_loss)\n            acc_values.append(epoch_acc)\n            print('\\n{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'validation' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model,acc_values,loss_values","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:09:55.391630Z","iopub.execute_input":"2021-11-21T07:09:55.391956Z","iopub.status.idle":"2021-11-21T07:09:55.418901Z","shell.execute_reply.started":"2021-11-21T07:09:55.391903Z","shell.execute_reply":"2021-11-21T07:09:55.417689Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"def visualize_model(model, num_images=6):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    fig = plt.figure()\n\n    with torch.no_grad():\n        for i, (inputs, labels,_) in enumerate(dataloaders['validation']):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n\n            for j in range(inputs.size()[0]):\n                images_so_far += 1\n                ax = plt.subplot(num_images//2, 2, images_so_far)\n                ax.axis('off')\n                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n                imshow(inputs.cpu().data[j])\n\n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:09:55.420550Z","iopub.execute_input":"2021-11-21T07:09:55.420978Z","iopub.status.idle":"2021-11-21T07:09:55.435717Z","shell.execute_reply.started":"2021-11-21T07:09:55.420930Z","shell.execute_reply":"2021-11-21T07:09:55.434540Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"\ndef test_model(model, criterion, optimizer):\n    labels_input=list()\n    labels_output=list()\n    vid_id = list()\n    for phase in ['validation']:\n        model.eval()\n\n        running_loss = 0.0\n        running_corrects = 0\n\n        for inputs, labels, fname in dataloaders[phase]:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            labels_input= labels_input + labels.tolist()\n            for f in fname:\n                vid_id.append(f.split('/')[-1].split('.')[0].split('_')[0])\n            outputs = model(inputs)\n            \n            loss = criterion(outputs, labels)\n            _, preds = torch.max(outputs, 1)\n            \n            labels_output= labels_output + preds.tolist()\n    return labels_input,labels_output,vid_id\n            \n","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:09:55.437098Z","iopub.execute_input":"2021-11-21T07:09:55.437608Z","iopub.status.idle":"2021-11-21T07:09:55.447636Z","shell.execute_reply.started":"2021-11-21T07:09:55.437558Z","shell.execute_reply":"2021-11-21T07:09:55.446736Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"from torch.optim import lr_scheduler\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nmodel_ft = model_ft.to(device)\n\nparams_to_update = []\nfor name,param in model_ft.named_parameters():\n    if param.requires_grad == True:\n        params_to_update.append(param)\n\noptimizer_conv = optim.SGD(params_to_update, lr=0.01, momentum=0.9)\n\ncriterion = nn.CrossEntropyLoss()\n# Decay LR by a factor of 0.1 every epoch\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=3, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:09:55.448984Z","iopub.execute_input":"2021-11-21T07:09:55.449655Z","iopub.status.idle":"2021-11-21T07:09:55.499571Z","shell.execute_reply.started":"2021-11-21T07:09:55.449545Z","shell.execute_reply":"2021-11-21T07:09:55.498920Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"model_ft,acc,loss = train_model(model_ft, criterion, optimizer_conv,\n                         exp_lr_scheduler, num_epochs=3, is_inception=False) # As an example, only show the results of 2 epoch","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:09:55.501025Z","iopub.execute_input":"2021-11-21T07:09:55.501287Z","iopub.status.idle":"2021-11-21T07:16:09.382906Z","shell.execute_reply.started":"2021-11-21T07:09:55.501242Z","shell.execute_reply":"2021-11-21T07:16:09.382015Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"def plot_history(history,loss,acc): \n    fig, ax1 = plt.subplots()\n    \n    ax1.plot(loss, 'r', label=\"training loss\")\n    ax1.grid(True)\n    ax1.set_xlabel('iteration')\n    ax1.set_ylabel('loss', color='r')\n    ax1.legend(loc=\"lower right\", fontsize=9)    \n    ax1.tick_params('y', colors='r')\n\n    ax2 = ax1.twinx()\n    ax2.plot(acc, 'b', label=\"training acc\")\n    ax2.legend(loc=\"upper right\", fontsize=9)\n    ax2.set_ylabel('acc', color='b')        \n    ax2.tick_params('y', colors='b')","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:16:09.384505Z","iopub.execute_input":"2021-11-21T07:16:09.385018Z","iopub.status.idle":"2021-11-21T07:16:09.392008Z","shell.execute_reply.started":"2021-11-21T07:16:09.384963Z","shell.execute_reply":"2021-11-21T07:16:09.391446Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"plot_history(model_ft,loss,acc)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:16:09.393242Z","iopub.execute_input":"2021-11-21T07:16:09.393672Z","iopub.status.idle":"2021-11-21T07:16:09.840478Z","shell.execute_reply.started":"2021-11-21T07:16:09.393579Z","shell.execute_reply":"2021-11-21T07:16:09.839536Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"\ny_true,y_pred,vid_id = test_model(model_ft, criterion, optimizer_conv)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:16:09.845209Z","iopub.execute_input":"2021-11-21T07:16:09.845664Z","iopub.status.idle":"2021-11-21T07:16:33.409760Z","shell.execute_reply.started":"2021-11-21T07:16:09.845469Z","shell.execute_reply":"2021-11-21T07:16:33.408850Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(y_true,y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:16:33.411594Z","iopub.execute_input":"2021-11-21T07:16:33.411888Z","iopub.status.idle":"2021-11-21T07:16:33.424271Z","shell.execute_reply.started":"2021-11-21T07:16:33.411839Z","shell.execute_reply":"2021-11-21T07:16:33.423118Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport glob\n\n\ndf = pd.DataFrame(list(zip(y_true,y_pred,vid_id)),columns =['y_true','y_pred','vid_id'])\ndf.to_csv('df.csv',encoding='utf-8',index=False)\n\nvid_list = list(set(df['vid_id'].values))\ny_true = []\ny_pred = []\nfor vid in vid_list:\n    #print(vid)\n    tmp_df = df[df['vid_id']==vid]\n    #print(len(tmp_df))\n    vid_pred = tmp_df['y_pred'].mode().values[0]\n    vid_label = tmp_df['y_true'].mode().values[0]\n    y_true.append(vid_label)\n    y_pred.append(vid_pred)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:16:33.426560Z","iopub.execute_input":"2021-11-21T07:16:33.427086Z","iopub.status.idle":"2021-11-21T07:16:33.493867Z","shell.execute_reply.started":"2021-11-21T07:16:33.427037Z","shell.execute_reply":"2021-11-21T07:16:33.493172Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"accuracy_score(y_true,y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T07:16:33.495049Z","iopub.execute_input":"2021-11-21T07:16:33.495511Z","iopub.status.idle":"2021-11-21T07:16:33.501316Z","shell.execute_reply.started":"2021-11-21T07:16:33.495318Z","shell.execute_reply":"2021-11-21T07:16:33.500573Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}